{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MA_xWDA1rRU3"
   },
   "source": [
    "## Generating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "id": "NFt8burwhz0e",
    "outputId": "7ea3cfc9-c231-477a-d966-d0d7c2128171"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print('Generating Training Data\\n')\n",
    "\n",
    "os.chdir('./Korean-license-plate-Generator')\n",
    "\n",
    "!mkdir ../Train_Images\n",
    "\n",
    "print('Augmentated Images Generating...\\n')\n",
    "!python ./Generator_augmentation.py --img_dir \"../Train_Images/\" --num 10000 --save True\n",
    "print('Augmentated Images Generated\\n')\n",
    "\n",
    "print('Original Images Generating...\\n')\n",
    "!python ./Generator_original.py --img_dir \"../Train_Images/\" --num 10000 --save True\n",
    "print('Original Images Generated\\n')\n",
    "\n",
    "print('Perspective Images Generating...\\n')\n",
    "!python ./Generator_perspective.py --img_dir \"../Train_Images/\" --num 10000 --save True\n",
    "print('Perspective Images Generated\\n')\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "158Cm3xUrUsd"
   },
   "source": [
    "## Generating Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "id": "Hz3w67AfrBD_",
    "outputId": "9d6ab57a-b3ce-478b-9e33-2bcf2d2f5f1b"
   },
   "outputs": [],
   "source": [
    "print('Generating Validation Data\\n')\n",
    "\n",
    "os.chdir('./Korean-license-plate-Generator')\n",
    "\n",
    "!mkdir ../Validation_Images\n",
    "\n",
    "print('Augmentated Images Generating...\\n')\n",
    "!python ./Generator_augmentation.py --img_dir \"../Validation_Images/\" --num 1000 --save True\n",
    "print('Augmentated Images Generated\\n')\n",
    "\n",
    "print('Original Images Generating...\\n')\n",
    "!python ./Generator_original.py --img_dir \"../Validation_Images/\" --num 1000 --save True\n",
    "print('Original Images Generated\\n')\n",
    "\n",
    "print('Perspective Images Generating...\\n')\n",
    "!python ./Generator_perspective.py --img_dir \"../Validation_Images/\" --num 1000 --save True\n",
    "print('Perspective Images Generated\\n')\n",
    "\n",
    "os.chdir('../')\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rLLHQ_aYfaoG"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "B_C9f53YfcxH",
    "outputId": "44680a2e-4e78-45da-f85b-0b2de2bd25eb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import os, random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import (\n",
    "    Conv2D, MaxPooling2D,\n",
    "    Input, Dense, Activation,\n",
    "    Reshape, Lambda,\n",
    "    BatchNormalization, LSTM#CuDNNLSTM\n",
    ")\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_SzcB4YofYLf"
   },
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "7sZRVpZZfSTx",
    "outputId": "36b1545a-dd2a-4b15-8940-16224469cdcf"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-cb1331d26adc>:17: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\nInstructions for updating:\nSimply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    }
   ],
   "source": [
    "#CHAR_VECTOR = \"adefghjknqrstwABCDEFGHIJKLMNOPZ0123456789\"\n",
    "\n",
    "#letters = [letter for letter in CHAR_VECTOR]\n",
    "letters = [letter for letter in \"dkqtwABCDEFGHIJKLMNOP0123456789\"]\n",
    "\n",
    "num_classes = len(letters) + 1\n",
    "\n",
    "img_w, img_h = 128, 64\n",
    "\n",
    "# Network parameters\n",
    "batch_size = 128\n",
    "# val_batch_size = 16\n",
    "\n",
    "downsample_factor = 4\n",
    "max_text_len = 9\n",
    "\n",
    "K.set_learning_phase(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bigPXUNTqHOL"
   },
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ku5km-iYfkX3"
   },
   "outputs": [],
   "source": [
    "def labels_to_text(labels):\n",
    "    return ''.join(list(map(lambda x: letters[int(x)], labels)))\n",
    "\n",
    "def text_to_labels(text):\n",
    "    return list(map(lambda x: letters.index(x), text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzRP_pG4xI-h"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, image_path, batch_size, image_width, image_height, downsample_factor, shuffle = True, max_text_len = 9):\n",
    "        '''Datagenerator'''\n",
    "        self.image_path = image_path\n",
    "        self.image_list = glob(self.image_path + '/*')\n",
    "        self.batch_size = batch_size\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.shuffle = shuffle\n",
    "        self.max_text_len = max_text_len\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        '''Denotes the number of batches per epoch'''\n",
    "        return int(np.floor(len(self.image_list) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''Generate Single Batch of Data'''\n",
    "        \n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.image_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        inputs, outputs = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return inputs, outputs\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        '''Updates indexes after each epoch'''\n",
    "        self.indexes = np.arange(len(self.image_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        '''Generates data containing batch_size samples'''\n",
    "        \n",
    "        # Reading Data\n",
    "        images = []\n",
    "        texts = []\n",
    "        label_length = np.zeros((self.batch_size, 1))\n",
    "        \n",
    "        for i, img_file in enumerate(list_IDs_temp):\n",
    "            image = cv2.imread(img_file, cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (self.image_width, self.image_height))\n",
    "            image = image.astype(np.float32)\n",
    "            image = (image / 255.0)\n",
    "            images.append(image.T)\n",
    "            imname = os.path.basename(img_file)\n",
    "            text = imname[0 : 9]#.split('/')[-1]\n",
    "            texts.append(text_to_labels(text))\n",
    "            label_length[i] = len(text)\n",
    "            # images[i, :, :] = image\n",
    "        \n",
    "        input_length = np.ones((self.batch_size, 1)) * (self.image_width // self.downsample_factor - 2)\n",
    "        images = np.expand_dims(np.array(images), axis = 3)\n",
    "        \n",
    "        inputs = {\n",
    "            'the_input': images,  # (bs, 128, 64, 1)\n",
    "            'the_labels': np.array(texts),  # (bs, 8)\n",
    "            'input_length': input_length,  # (bs, 1) \n",
    "            'label_length': np.array(label_length)  # (bs, 1)\n",
    "        }\n",
    "\n",
    "        outputs = {'ctc': np.zeros([self.batch_size])} # (bs, 1) \n",
    "\n",
    "        return (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0BzCXU6v2k_Y"
   },
   "outputs": [],
   "source": [
    "datagen = DataGenerator('Korean-license-plate-Generator/Train', batch_size, 128, 64, 4, True, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "colab_type": "code",
    "id": "odLt_fPCTIFf",
    "outputId": "83990970-601f-4fb8-ba7c-3f6212e05d2c"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 4, ncols = 2, figsize = (16, 16))\n",
    "plt.setp(axes.flat, xticks = [], yticks = [])\n",
    "inp, out = datagen.__getitem__(0)\n",
    "c = 1\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(inp['the_input'][c].reshape(img_w, img_h).T)\n",
    "    ax.set_xlabel(labels_to_text(inp['the_labels'][c]))\n",
    "    c += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fwjuyCgqLrS"
   },
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EKS7zKMbf_Gb"
   },
   "outputs": [],
   "source": [
    "# # Loss and train functions, network architecture\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5A4hOZSsga3G"
   },
   "outputs": [],
   "source": [
    "def get_Model(training):\n",
    "    input_shape = (img_w, img_h, 1)     # (128, 64, 1)\n",
    "\n",
    "    # Make Networkw\n",
    "    inputs = Input(name='the_input', shape=input_shape, dtype='float32')  # (None, 128, 64, 1)\n",
    "\n",
    "    # Convolution layer (VGG)\n",
    "    inner = Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs)  # (None, 128, 64, 64)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)  # (None,64, 32, 64)\n",
    "\n",
    "    inner = Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  # (None, 64, 32, 128)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)  # (None, 32, 16, 128)\n",
    "\n",
    "    inner = Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  # (None, 32, 16, 256)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)  # (None, 32, 8, 256)\n",
    "\n",
    "    inner = Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(inner)  # (None, 32, 8, 512)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = Conv2D(512, (3, 3), padding='same', name='conv6')(inner)  # (None, 32, 8, 512)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "    inner = MaxPooling2D(pool_size=(1, 2), name='max4')(inner)  # (None, 32, 4, 512)\n",
    "\n",
    "    inner = Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(inner)  # (None, 32, 4, 512)\n",
    "    inner = BatchNormalization()(inner)\n",
    "    inner = Activation('relu')(inner)\n",
    "\n",
    "    # CNN to RNN\n",
    "    inner = Reshape(target_shape=((32, 2048)), name='reshape')(inner)  # (None, 32, 2048)\n",
    "    inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)  # (None, 32, 64)\n",
    "    # RNN layer\n",
    "    lstm_1 = LSTM(256, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(inner)\n",
    "    lstm_1b = LSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(inner)\n",
    "    # lstm_1 = CuDNNLSTM(256, return_sequences=True, kernel_initializer='he_normal', name='lstm1')(inner)  # (None, 32, 512)\n",
    "    # lstm_1b = CuDNNLSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm1_b')(inner)\n",
    "    lstm1_merged = add([lstm_1, lstm_1b])  # (None, 32, 512)\n",
    "    #reversed_lstm_1b = Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_1b)\n",
    "\n",
    "    #lstm1_merged = add([lstm_1, reversed_lstm_1b])  # (None, 32, 512)\n",
    "    lstm1_merged = BatchNormalization()(lstm1_merged)\n",
    "    lstm_2 = LSTM(256, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)\n",
    "    lstm_2b = LSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)\n",
    "    # lstm_2 = CuDNNLSTM(256, return_sequences=True, kernel_initializer='he_normal', name='lstm2')(lstm1_merged)\n",
    "    # lstm_2b = CuDNNLSTM(256, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='lstm2_b')(lstm1_merged)\n",
    "    lstm2_merged = concatenate([lstm_2, lstm_2b])  # (None, 32, 1024)\n",
    "    #reversed_lstm_2b= Lambda(lambda inputTensor: K.reverse(inputTensor, axes=1)) (lstm_2b)\n",
    "\n",
    "    #lstm2_merged = concatenate([lstm_2, reversed_lstm_2b])  # (None, 32, 1024)\n",
    "    lstm_merged = BatchNormalization()(lstm2_merged)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    inner = Dense(num_classes, kernel_initializer='he_normal',name='dense2')(lstm2_merged) #(None, 32, 63)\n",
    "    y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "    labels = Input(name='the_labels', shape=[max_text_len], dtype='float32') # (None ,8)\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')     # (None, 1)\n",
    "\n",
    "    # Keras doesn't currently support loss funcs with extra parameters\n",
    "    # so CTC loss is implemented in a lambda layer\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n",
    "\n",
    "    if training:\n",
    "        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "    else:\n",
    "        return Model(inputs=[inputs], outputs=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-Y4Cr-3ngrxP",
    "outputId": "1d04f3b9-59dc-4830-ef53-2424749ed28f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nthe_input (InputLayer)          [(None, 128, 64, 1)] 0                                            \n__________________________________________________________________________________________________\nconv1 (Conv2D)                  (None, 128, 64, 64)  640         the_input[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 128, 64, 64)  256         conv1[0][0]                      \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 128, 64, 64)  0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\nmax1 (MaxPooling2D)             (None, 64, 32, 64)   0           activation[0][0]                 \n__________________________________________________________________________________________________\nconv2 (Conv2D)                  (None, 64, 32, 128)  73856       max1[0][0]                       \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 64, 32, 128)  512         conv2[0][0]                      \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 64, 32, 128)  0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nmax2 (MaxPooling2D)             (None, 32, 16, 128)  0           activation_1[0][0]               \n__________________________________________________________________________________________________\nconv3 (Conv2D)                  (None, 32, 16, 256)  295168      max2[0][0]                       \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 32, 16, 256)  1024        conv3[0][0]                      \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 32, 16, 256)  0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv4 (Conv2D)                  (None, 32, 16, 256)  590080      activation_2[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 32, 16, 256)  1024        conv4[0][0]                      \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 32, 16, 256)  0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nmax3 (MaxPooling2D)             (None, 32, 8, 256)   0           activation_3[0][0]               \n__________________________________________________________________________________________________\nconv5 (Conv2D)                  (None, 32, 8, 512)   1180160     max3[0][0]                       \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 32, 8, 512)   2048        conv5[0][0]                      \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 32, 8, 512)   0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconv6 (Conv2D)                  (None, 32, 8, 512)   2359808     activation_4[0][0]               \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 32, 8, 512)   2048        conv6[0][0]                      \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 32, 8, 512)   0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nmax4 (MaxPooling2D)             (None, 32, 4, 512)   0           activation_5[0][0]               \n__________________________________________________________________________________________________\ncon7 (Conv2D)                   (None, 32, 4, 512)   1049088     max4[0][0]                       \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 32, 4, 512)   2048        con7[0][0]                       \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 32, 4, 512)   0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\nreshape (Reshape)               (None, 32, 2048)     0           activation_6[0][0]               \n__________________________________________________________________________________________________\ndense1 (Dense)                  (None, 32, 64)       131136      reshape[0][0]                    \n__________________________________________________________________________________________________\nlstm1_b (LSTM)                  (None, 32, 256)      328704      dense1[0][0]                     \n__________________________________________________________________________________________________\nlstm1 (LSTM)                    (None, 32, 256)      328704      dense1[0][0]                     \n__________________________________________________________________________________________________\nlambda (Lambda)                 (None, 32, 256)      0           lstm1_b[0][0]                    \n__________________________________________________________________________________________________\nadd (Add)                       (None, 32, 256)      0           lstm1[0][0]                      \n                                                                 lambda[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 32, 256)      1024        add[0][0]                        \n__________________________________________________________________________________________________\nlstm2_b (LSTM)                  (None, 32, 256)      525312      batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nlstm2 (LSTM)                    (None, 32, 256)      525312      batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 32, 256)      0           lstm2_b[0][0]                    \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 32, 512)      0           lstm2[0][0]                      \n                                                                 lambda_1[0][0]                   \n__________________________________________________________________________________________________\ndense2 (Dense)                  (None, 32, 32)       16416       concatenate[0][0]                \n__________________________________________________________________________________________________\nsoftmax (Activation)            (None, 32, 32)       0           dense2[0][0]                     \n__________________________________________________________________________________________________\nthe_labels (InputLayer)         [(None, 9)]          0                                            \n__________________________________________________________________________________________________\ninput_length (InputLayer)       [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nlabel_length (InputLayer)       [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n                                                                 the_labels[0][0]                 \n                                                                 input_length[0][0]               \n                                                                 label_length[0][0]               \n==================================================================================================\nTotal params: 7,414,368\nTrainable params: 7,409,376\nNon-trainable params: 4,992\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_Model(training = True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MK8K4KuFsctb",
    "outputId": "35e422f9-d39a-4d68-aac1-1b4fd3350462"
   },
   "outputs": [],
   "source": [
    "plot_model(\n",
    "    model,\n",
    "    to_file = 'model.png',\n",
    "    show_shapes = True,\n",
    "    show_layer_names = True,\n",
    "    rankdir = 'TB'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gQLlo9pTqTj8"
   },
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "pFGBpGnlmA9l",
    "outputId": "4ae8226c-851b-43dc-99e5-517cde194349"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = {'ctc': lambda y_true, y_pred: y_pred}, optimizer = Adadelta())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0U_NmQRhJKQ"
   },
   "outputs": [],
   "source": [
    "train_datagen = DataGenerator('Korean-license-plate-Generator/Train', batch_size, img_w, img_h, downsample_factor, True, max_text_len)\n",
    "valid_datagen = DataGenerator('Korean-license-plate-Generator/Val', batch_size, img_w, img_h, downsample_factor, True, max_text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iSphFtYZmLED"
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor = 'val_loss', min_delta = 0.001,\n",
    "    patience = 4, mode = 'min',\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath = 'CuDNNLSTM+BN5--{epoch:02d}--{loss:.3f}--{val_loss:.3f}.hdf5',\n",
    "    monitor = 'val_loss', verbose = 1,\n",
    "    mode = 'min', save_freq = 'epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6-55Ru8hmaTT",
    "outputId": "a76394c4-d793-4f91-ae7d-1a5a29bbd10e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-5e0a7e09a8ab>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 40.3584\n",
      "Epoch 00001: saving model to CuDNNLSTM+BN5--01--40.358--29.769.hdf5\n",
      "1171/1171 [==============================] - 1506s 1s/step - loss: 40.3584 - val_loss: 29.7691\n",
      "Epoch 2/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 27.4556\n",
      "Epoch 00002: saving model to CuDNNLSTM+BN5--02--27.456--25.745.hdf5\n",
      "1171/1171 [==============================] - 1435s 1s/step - loss: 27.4556 - val_loss: 25.7448\n",
      "Epoch 3/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 24.7748\n",
      "Epoch 00003: saving model to CuDNNLSTM+BN5--03--24.775--23.874.hdf5\n",
      "1171/1171 [==============================] - 404s 345ms/step - loss: 24.7748 - val_loss: 23.8743\n",
      "Epoch 4/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 23.2352\n",
      "Epoch 00004: saving model to CuDNNLSTM+BN5--04--23.235--22.568.hdf5\n",
      "1171/1171 [==============================] - 218s 186ms/step - loss: 23.2352 - val_loss: 22.5678\n",
      "Epoch 5/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 22.0521\n",
      "Epoch 00005: saving model to CuDNNLSTM+BN5--05--22.052--21.504.hdf5\n",
      "1171/1171 [==============================] - 214s 183ms/step - loss: 22.0521 - val_loss: 21.5044\n",
      "Epoch 6/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 21.0580\n",
      "Epoch 00006: saving model to CuDNNLSTM+BN5--06--21.058--20.597.hdf5\n",
      "1171/1171 [==============================] - 216s 184ms/step - loss: 21.0580 - val_loss: 20.5966\n",
      "Epoch 7/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 20.2191\n",
      "Epoch 00007: saving model to CuDNNLSTM+BN5--07--20.219--19.839.hdf5\n",
      "1171/1171 [==============================] - 316s 270ms/step - loss: 20.2191 - val_loss: 19.8386\n",
      "Epoch 8/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 19.5171\n",
      "Epoch 00008: saving model to CuDNNLSTM+BN5--08--19.517--19.201.hdf5\n",
      "1171/1171 [==============================] - 217s 185ms/step - loss: 19.5171 - val_loss: 19.2006\n",
      "Epoch 9/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 18.9169\n",
      "Epoch 00009: saving model to CuDNNLSTM+BN5--09--18.917--18.651.hdf5\n",
      "1171/1171 [==============================] - 217s 185ms/step - loss: 18.9169 - val_loss: 18.6505\n",
      "Epoch 10/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 18.3868\n",
      "Epoch 00010: saving model to CuDNNLSTM+BN5--10--18.387--18.154.hdf5\n",
      "1171/1171 [==============================] - 217s 185ms/step - loss: 18.3868 - val_loss: 18.1536\n",
      "Epoch 11/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 17.9054\n",
      "Epoch 00011: saving model to CuDNNLSTM+BN5--11--17.905--17.696.hdf5\n",
      "1171/1171 [==============================] - 216s 184ms/step - loss: 17.9054 - val_loss: 17.6959\n",
      "Epoch 12/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 17.4566\n",
      "Epoch 00012: saving model to CuDNNLSTM+BN5--12--17.457--17.266.hdf5\n",
      "1171/1171 [==============================] - 213s 182ms/step - loss: 17.4566 - val_loss: 17.2663\n",
      "Epoch 13/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 17.0283\n",
      "Epoch 00013: saving model to CuDNNLSTM+BN5--13--17.028--16.848.hdf5\n",
      "1171/1171 [==============================] - 205s 175ms/step - loss: 17.0283 - val_loss: 16.8480\n",
      "Epoch 14/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 16.6163\n",
      "Epoch 00014: saving model to CuDNNLSTM+BN5--14--16.616--16.461.hdf5\n",
      "1171/1171 [==============================] - 201s 172ms/step - loss: 16.6163 - val_loss: 16.4614\n",
      "Epoch 15/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 16.2225\n",
      "Epoch 00015: saving model to CuDNNLSTM+BN5--15--16.223--16.070.hdf5\n",
      "1171/1171 [==============================] - 205s 175ms/step - loss: 16.2225 - val_loss: 16.0703\n",
      "Epoch 16/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 15.8438\n",
      "Epoch 00016: saving model to CuDNNLSTM+BN5--16--15.844--15.713.hdf5\n",
      "1171/1171 [==============================] - 209s 179ms/step - loss: 15.8438 - val_loss: 15.7134\n",
      "Epoch 17/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 15.4724\n",
      "Epoch 00017: saving model to CuDNNLSTM+BN5--17--15.472--15.346.hdf5\n",
      "1171/1171 [==============================] - 204s 174ms/step - loss: 15.4724 - val_loss: 15.3464\n",
      "Epoch 18/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 15.1099\n",
      "Epoch 00018: saving model to CuDNNLSTM+BN5--18--15.110--14.994.hdf5\n",
      "1171/1171 [==============================] - 324s 277ms/step - loss: 15.1099 - val_loss: 14.9942\n",
      "Epoch 19/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 14.7548\n",
      "Epoch 00019: saving model to CuDNNLSTM+BN5--19--14.755--14.656.hdf5\n",
      "1171/1171 [==============================] - 209s 179ms/step - loss: 14.7548 - val_loss: 14.6562\n",
      "Epoch 20/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 14.4090\n",
      "Epoch 00020: saving model to CuDNNLSTM+BN5--20--14.409--14.311.hdf5\n",
      "1171/1171 [==============================] - 212s 181ms/step - loss: 14.4090 - val_loss: 14.3106\n",
      "Epoch 21/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 14.0723\n",
      "Epoch 00021: saving model to CuDNNLSTM+BN5--21--14.072--13.992.hdf5\n",
      "1171/1171 [==============================] - 214s 182ms/step - loss: 14.0723 - val_loss: 13.9916\n",
      "Epoch 22/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 13.7429\n",
      "Epoch 00022: saving model to CuDNNLSTM+BN5--22--13.743--13.668.hdf5\n",
      "1171/1171 [==============================] - 215s 183ms/step - loss: 13.7429 - val_loss: 13.6678\n",
      "Epoch 23/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 13.4178\n",
      "Epoch 00023: saving model to CuDNNLSTM+BN5--23--13.418--13.341.hdf5\n",
      "1171/1171 [==============================] - 223s 190ms/step - loss: 13.4178 - val_loss: 13.3410\n",
      "Epoch 24/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 13.0975\n",
      "Epoch 00024: saving model to CuDNNLSTM+BN5--24--13.097--13.027.hdf5\n",
      "1171/1171 [==============================] - 215s 183ms/step - loss: 13.0975 - val_loss: 13.0271\n",
      "Epoch 25/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 12.7803\n",
      "Epoch 00025: saving model to CuDNNLSTM+BN5--25--12.780--12.730.hdf5\n",
      "1171/1171 [==============================] - 210s 179ms/step - loss: 12.7803 - val_loss: 12.7303\n",
      "Epoch 26/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 12.4637\n",
      "Epoch 00026: saving model to CuDNNLSTM+BN5--26--12.464--12.395.hdf5\n",
      "1171/1171 [==============================] - 212s 181ms/step - loss: 12.4637 - val_loss: 12.3949\n",
      "Epoch 27/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 12.1543\n",
      "Epoch 00027: saving model to CuDNNLSTM+BN5--27--12.154--12.093.hdf5\n",
      "1171/1171 [==============================] - 207s 177ms/step - loss: 12.1543 - val_loss: 12.0935\n",
      "Epoch 28/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 11.8356\n",
      "Epoch 00028: saving model to CuDNNLSTM+BN5--28--11.836--11.775.hdf5\n",
      "1171/1171 [==============================] - 205s 175ms/step - loss: 11.8356 - val_loss: 11.7753\n",
      "Epoch 29/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 11.5230\n",
      "Epoch 00029: saving model to CuDNNLSTM+BN5--29--11.523--11.485.hdf5\n",
      "1171/1171 [==============================] - 206s 176ms/step - loss: 11.5230 - val_loss: 11.4852\n",
      "Epoch 30/30\n",
      "1171/1171 [==============================] - ETA: 0s - loss: 11.2113\n",
      "Epoch 00030: saving model to CuDNNLSTM+BN5--30--11.211--11.158.hdf5\n",
      "1171/1171 [==============================] - 209s 179ms/step - loss: 11.2113 - val_loss: 11.1576\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    history = model.fit_generator(\n",
    "        generator = train_datagen,\n",
    "        steps_per_epoch = int(len(train_datagen.image_list) // batch_size),\n",
    "        epochs = 30, callbacks = [checkpoint],\n",
    "        validation_data = valid_datagen,\n",
    "        validation_steps = int(len(valid_datagen.image_list) // batch_size)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "DtCddG7Vm61Z",
    "outputId": "6b28e4f0-7f71-4555-a923-74b0a814ea6f"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], color = 'b')\n",
    "plt.plot(history.history['val_loss'], color = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVnRcKV72V5z"
   },
   "outputs": [],
   "source": [
    "Region = {\"A\": \"서울 \", \"B\": \"경기 \", \"C\": \"인천 \", \"D\": \"강원 \", \"E\": \"충남 \", \"F\": \"대전 \",\n",
    "          \"G\": \"충북 \", \"H\": \"부산 \", \"I\": \"울산 \", \"J\": \"대구 \", \"K\": \"경북 \", \"L\": \"경남 \",\n",
    "          \"M\": \"전남 \", \"N\": \"광주 \", \"O\": \"전북 \", \"P\": \"제주 \"}\n",
    "Hangul = {\"dk\": \"아\", \"wk\": \"자\", \"tk\": \"사\", \"qk\": \"바\"}\n",
    "# Hangul = {\"dk\": \"아\", \"dj\": \"어\", \"dh\": \"오\", \"dn\": \"우\", \"qk\": \"바\", \"qj\": \"버\", \"qh\": \"보\", \"qn\": \"부\",\n",
    "#           \"ek\": \"다\", \"ej\": \"더\", \"eh\": \"도\", \"en\": \"두\", \"rk\": \"가\", \"rj\": \"거\", \"rh\": \"고\", \"rn\": \"구\",\n",
    "#           \"wk\": \"자\", \"wj\": \"저\", \"wh\": \"조\", \"wn\": \"주\", \"ak\": \"마\", \"aj\": \"머\", \"ah\": \"모\", \"an\": \"무\",\n",
    "#           \"sk\": \"나\", \"sj\": \"너\", \"sh\": \"노\", \"sn\": \"누\", \"fk\": \"라\", \"fj\": \"러\", \"fh\": \"로\", \"fn\": \"루\",\n",
    "#           \"tk\": \"사\", \"tj\": \"서\", \"th\": \"소\", \"tn\": \"수\", \"gj\": \"허\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4sqYFy42dqN"
   },
   "outputs": [],
   "source": [
    "def decode_label(out):\n",
    "    # out : (1, 32, 42)\n",
    "    out_best = list(np.argmax(out[0, 2:], axis=1))  # get max index -> len = 32\n",
    "    out_best = [k for k, g in itertools.groupby(out_best)]  # remove overlap value\n",
    "    outstr = ''\n",
    "    for i in out_best:\n",
    "        if i < len(letters):\n",
    "            outstr += letters[i]\n",
    "    return outstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ftDX7_qT2f6q"
   },
   "outputs": [],
   "source": [
    "def label_to_hangul(label):  # eng -> hangul\n",
    "    region = label[0]\n",
    "    two_num = label[1:3]\n",
    "    hangul = label[3:5]\n",
    "    four_num = label[5:9]\n",
    "\n",
    "    try:\n",
    "        region = Region[region] if region != 'Z' else ''\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        hangul = Hangul[hangul]\n",
    "    except:\n",
    "        pass\n",
    "    return region + two_num + hangul + four_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "rVRyFCqn2iif",
    "outputId": "08fcccbf-b3e7-45d7-8672-7beb24f4af5c"
   },
   "outputs": [],
   "source": [
    "inference = get_Model(training = False)\n",
    "inference.load_weights('CuDNNLSTM+BN5--29--0.211--0.319.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V7nl4vO_2tJY",
    "outputId": "9ed55a3a-9aab-48bc-ee3c-f402c5a05444"
   },
   "outputs": [],
   "source": [
    "inp, out = valid_datagen.__getitem__(0)\n",
    "images = inp['the_input']\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "hb6zZw_V3CwI",
    "outputId": "579be1e5-7173-4bc9-d05e-b07fce9ba3db"
   },
   "outputs": [],
   "source": [
    "predictions = inference.predict(images[0].reshape(1, img_w, img_h, 1), verbose = 1)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZrZO6UVt3Ifd",
    "outputId": "ec05cf68-dfee-4196-84bb-9f2be28b3da5"
   },
   "outputs": [],
   "source": [
    "pred_texts = decode_label(predictions)\n",
    "pred_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "colab_type": "code",
    "id": "ueltNMeG3K1B",
    "outputId": "875664e8-9017-492d-d4f4-a63546fc9a9a"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[0].reshape(img_w, img_h).T)\n",
    "plt.title(pred_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 930
    },
    "colab_type": "code",
    "id": "9WYdxeoP3TVI",
    "outputId": "72632de7-f956-48e1-8ee9-8382d145121d"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 4, ncols = 2, figsize = (16, 16))\n",
    "plt.setp(axes.flat, xticks = [], yticks = [])\n",
    "c = 1\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image = inp['the_input'][c].reshape(1, img_w, img_h, 1)\n",
    "    prediction = model.predict(image)\n",
    "    ax.imshow(image.reshape(img_w, img_h).T)\n",
    "    ax.set_xlabel(decode_label(prediction) + '\\n' + 'Hangul: ' + label_to_hangul(decode_label(prediction)))\n",
    "    c += 1\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Korean_License_Plate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "682bbf7e9d9dd2b5aacb34e122bd3cad1c54c2accd453c99d2ca58a9d804ec4c"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}